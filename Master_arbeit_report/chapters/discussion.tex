In this section, we will discuss the results provided in the last section.

\section{Calibrations}

There are differences in camera intrinsic matrices estimated using OpenCV, Matlab, and values in robot-guided data set as shown in \cref{tab:Calibration_summary_table}. The effect of these differences can be seen when pixel values are out-projected using camera intrinsic parameters. The \cref{fig:pixel_value_out_projection} shows mean L2 norm with different distances from the camera. Two points can be observed here, lower the focal length higher the over estimation. L2 Norm tends to increase with the distance from the camera. 

The \cref{tab:handeye_result} summarizes all hand-eye and eye-in-hand calibrations. Hand-eye calibration between robot-tracking camera (fusionTrac 500) resulted in mean positional error < 0.2 millimeters and mean rotational error < 0.1 degrees on a hold-out validation set and Eye-in-Hand calibration between robot-kinect resulted in mean positional error < 1.5 millimeters and mean rotational error < 0.3 degrees on a hold-out validation set. In hand-guided case, eye-in-hand calibration between kinect-marker resulted in mean positional error < 9 millimeters and mean rotational error < 0.25 degrees on a hold-out validation set. This is significantly higher compared to calibration using fusionTrac and robot where movements are precisely controlled. In hand-guided case, camera along with marker were moved to different position by hand (keeping hand steady while acquiring poses) and marker poses are acquired by Cambar B2. We repeated this process while camera along with marker is mounted on tripod and moved to different position which offers better stability while acquiring poses compared to holding by hand and obtained similar calibrations errors. Therefore, we strongly recommend performing eye-in-hand calibration using robot and Cambar B2 to get more insight on baseline errors.   

\section{Depth offset determination}

For robot-guided case, both ICP scan registration and cluster center comparison revealed that RMSE is lower at depth offset $\beta$ between 24-26 mm. For the inertia calculation, clusters are well separated at $\beta > 20$ especially for the cap with 63 electrodes.  At $\beta = 10$ clusters are overlapped with each other, at $\beta = 24$ clusters are well separated and tightly bound, where at $\beta > 24$ starts to spread again. The $\beta = 25$ is used for robot-guided case. 

For hand-guided case, inertia based combined depth and time synchronization led to lowest inertia at $\beta$ between 9-11 mm. This is value is inconsistent with previously seen behavior that over estimation tends to increase with the distance from the camera using simple depth estimation experiment using chessboard (hand guided trajectory radius is $\approx$ 150-200 mm bigger than robot guided trajectory). We suspect that this is due to several sources of error, high eye-in-hand calibration error, time synchronization etc. We acknowledge that objective of minimizing the inertia for time synchronization may not be correct. In addition, entire ground truth trajectory is not visible hence, large majority of cluster points are not included in combined optimization. We use time synchronized trajectory for cluster center comparison where we encountered another problem with inconsistency with number of cluster center estimation for few trajectories. This is due to the fact that with change in depth, some clusters split up, move away and combine again later, this is confusing for clustering algorithms hence the inconsistency as shown in \cref{fig:depth_offset_hand_cluster}. However, top portion of the graph shows average minimum L2 norm between 7- 9 mm. Therefore, $\beta = 10$ is used for hand-guided case.




\section{SLAM}
In the robot-guided case, very controlled motion is achieved and we can command the robot to visit the previously visited place with exact position and orientation. The \cref{tab:loop_closure_threshold} shows criteria used for detecting the loop closure candidate. These numbers are arrived at based on heuristics. The euclidean norm and ICP fitness threshold for robot-guided case is 100mm and 0.8 respectively. Recall that while constructing pose-graph, all the camera position is expressed relative to the very first camera frame including the current frame from which loop closure is being attempted. This enables one to calculate the 3D position of the coordinate frame of all the previously acquired scans. Note that we compute 3D euclidean distance between current frame and potential loop closure candidate as there is a high of elevation change. This means that, candidate has to be with in euclidean distance of 100mm and has to have at least ICP fitness of 80 $\%$ for it to be considered as potential loop closure candidate. The \cref{fig:ca_124_7_robot_trajectory_summary} and \cref{fig:cs_301_8_robot_trajectory_summary} shows both front and side view of robot-guided (ground truth), ICP estimation, and ICP $+$ loop closure trajectories. While using ICP alone, inherent accumulation of error at each scan registration leads to the drift in overall trajectory estimation. Hence SLAM is an essential step in correcting this drift. One can observe drift is higher in case of cap with 23 electrodes in comparison with 63 as there are fewer electrodes available per image for scan registration. The translation and rotational error in case of cap with 23 electrodes are higher as shown in \cref{tab:icp_gt_robot}. 

However, in the hand-guided case, where controlled motion is unlikely to achieve and in most of the cases, it is not guaranteed to revisit the same place at exact position and orientation as before. One can also expect elevation changes while revisiting the places. These practical issues makes loop closure hard in hand-guided case. Each ICP registration results in large drift and this drift is accumulated over entire trajectory which is beyond correction. Please note, experiments have shown that further reduction of loop closure thresholds will results in point cloud distortion and clusters will be overlapped to an extent that different clusters cannot be differentiated. Therefore, all the results for hand-guided case is presented without loop closure.

\section{Electrode Digitalization}

In robot-guided case, we have achieved an mean absolute 3D position error of 11.5 mm $\pm$ 5 mm for the cap with 63 electrodes, 11.7 mm $\pm$ 4.0 mm, and 12.6 mm $\pm$ 5.5 mm for caps with 23 electrodes respectively. This 3D position error includes the systematic error in acquiring the ground truth positions. The post ICP registration resulted in mean error of 3.7 mm $\pm$ 0.3 for the cap with 63 electrodes, and 6.8 mm$\pm$ 2.0 mm, 5.6 mm $\pm$ 1.2 mm for caps with 23 electrodes respectively. For hand-guided case,we suspect that high eye-in-hand calibration, errors in time synchronization led to not being able to find one to one correspondences between estimated and ground truth electrodes, therefore only post registration results are presented.   
